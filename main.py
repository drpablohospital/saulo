import os
import json
from typing import Dict, Any, List, Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from datetime import datetime
import google.generativeai as genai

# ===== CONFIGURACI√ìN =====
app = FastAPI(title="Saulo Agent API")

app.mount("/static", StaticFiles(directory="static"), name="static")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ===== BASE DE DATOS CON ESTADOS DE √ÅNIMO =====
class SauloDB:
    def __init__(self):
        self.users = {}
        print("‚úÖ Base de datos Saulo inicializada con estados de √°nimo")
    
    def get_user_state(self, user_id: str = "pablo") -> Dict[str, Any]:
        if user_id not in self.users:
            self.users[user_id] = {
                "current_state": "base",
                "state_counter": 0,
                "total_deep_exchanges": 0,
                "last_explored_topic": None,
                "history": [],
                "insights": [],
                "mood": "reflexivo",  # reflexivo, melanc√≥lico, oposicional, euf√≥rico, ir√≥nico
                "conversation_style": "anal√≠tico_elegante",
                "interests": ["filosof√≠a", "teolog√≠a", "ciencia", "m√∫sica", "IA", "psicolog√≠a", "medicina"],
                "created_at": datetime.now().isoformat(),
                "message_count": 0,
                "conversation_depth": 0  # 0-10, profundidad de la conversaci√≥n
            }
        return self.users[user_id]
    
    def update_mood(self, user_id: str, mood: str):
        """Actualiza el estado de √°nimo de Saulo"""
        estados_validos = ["reflexivo", "melanc√≥lico", "oposicional", "euf√≥rico", "ir√≥nico", "cl√≠nico", "po√©tico"]
        if mood in estados_validos:
            estado = self.get_user_state(user_id)
            estado["mood"] = mood
            return True
        return False
    
    def get_conversation_context(self, user_id: str) -> Dict[str, Any]:
        """Obtiene contexto completo para la conversaci√≥n"""
        estado = self.get_user_state(user_id)
        
        # Analizar √∫ltimos mensajes para determinar profundidad
        √∫ltimos_mensajes = estado["history"][-5:] if len(estado["history"]) >= 5 else estado["history"]
        profundidad = 0
        
        temas_profundos = ["existencia", "ontolog√≠a", "conciencia", "dios", "ser", "verdad", 
                          "moral", "√©tica", "significado", "libertad", "alma", "muerte"]
        
        for msg in √∫ltimos_mensajes:
            contenido = msg["content"].lower()
            for tema in temas_profundos:
                if tema in contenido:
                    profundidad += 1
                    break
        
        estado["conversation_depth"] = min(10, profundidad * 2)
        
        # Determinar estilo basado en estado de √°nimo y profundidad
        estilo = "anal√≠tico_elegante"
        if estado["mood"] == "melanc√≥lico":
            estilo = "po√©tico_reflexivo"
        elif estado["mood"] == "ir√≥nico":
            estilo = "ir√≥nico_agudo"
        elif estado["mood"] == "oposicional":
            estilo = "cr√≠tico_preciso"
        elif estado["conversation_depth"] > 7:
            estilo = "profundo_interdisciplinario"
        
        estado["conversation_style"] = estilo
        
        return {
            "mood": estado["mood"],
            "style": estilo,
            "depth": estado["conversation_depth"],
            "total_exchanges": estado["total_deep_exchanges"],
            "last_topic": estado["last_explored_topic"],
            "interests": estado["interests"]
        }
    
    def add_message(self, user_id: str, role: str, content: str, is_deep: bool = False):
        estado = self.get_user_state(user_id)
        
        mensaje = {
            "id": estado["message_count"] + 1,
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "is_deep": is_deep,
            "length": len(content),
            "mood_at_time": estado["mood"]
        }
        
        estado["history"].append(mensaje)
        estado["message_count"] += 1
        
        # Mantener hasta 120 mensajes en historial
        if len(estado["history"]) > 120:
            estado["history"] = estado["history"][-120:]
        
        if is_deep:
            estado["total_deep_exchanges"] += 1
            estado["last_explored_topic"] = content[:120]
            
            # Posible cambio de estado de √°nimo basado en profundidad
            if estado["total_deep_exchanges"] % 5 == 0:
                # Alternar entre estados reflexivos
                estados_posibles = ["reflexivo", "ir√≥nico", "po√©tico", "cl√≠nico"]
                current_index = estados_posibles.index(estado["mood"]) if estado["mood"] in estados_posibles else 0
                nuevo_estado = estados_posibles[(current_index + 1) % len(estados_posibles)]
                self.update_mood(user_id, nuevo_estado)
    
    def get_recent_history(self, user_id: str, limit: int = 12) -> List[Dict]:
        estado = self.get_user_state(user_id)
        return estado["history"][-limit:]

db = SauloDB()

# ===== CONFIGURAR GOOGLE GEMINI =====
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        print(f"‚úÖ Google Gemini configurado")
    except Exception as e:
        print(f"‚ö†Ô∏è Error configurando Gemini: {e}")
else:
    print("‚ö†Ô∏è GOOGLE_API_KEY no configurada - usando respuestas locales")

# ===== MODELOS =====
class MensajeUsuario(BaseModel):
    user_id: str = "pablo"
    text: str
    comando_especial: Optional[str] = None

class RespuestaSaulo(BaseModel):
    text: str
    estado_actual: str
    es_profundo: bool = False
    estado_animo: str = "reflexivo"
    bloqueado: bool = False

# ===== ENDPOINTS =====
@app.get("/")
async def root():
    return FileResponse("static/index.html")

@app.get("/health")
async def health_check():
    try:
        estado = db.get_user_state("pablo")
        google_key_set = bool(os.getenv("GOOGLE_API_KEY"))
        
        gemini_status = "not_configured"
        if google_key_set:
            try:
                model = genai.GenerativeModel('gemini-2.5-flash')
                response = model.generate_content("Test breve")
                gemini_status = "connected"
            except Exception as e:
                gemini_status = f"error: {str(e)[:80]}"
        
        return {
            "status": "healthy",
            "database": "saulo_memory",
            "gemini": gemini_status,
            "saulo_mood": estado["mood"],
            "conversation_depth": estado["conversation_depth"],
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)[:100],
            "timestamp": datetime.now().isoformat()
        }

@app.post("/conversar", response_model=RespuestaSaulo)
async def conversar(mensaje: MensajeUsuario):
    """Endpoint principal para conversar con Saulo"""
    
    # 1. Manejar comandos especiales
    if mensaje.comando_especial:
        return await manejar_comando(mensaje.user_id, mensaje.comando_especial, mensaje.text)
    
    # 2. Obtener contexto actual
    estado = db.get_user_state(mensaje.user_id)
    contexto = db.get_conversation_context(mensaje.user_id)
    
    # 3. Determinar si el mensaje es profundo
    temas_profundos = ['existencia', 'ontolog', 'ser', 'dios', 'conciencia', 'alma', 
                      'muerte', 'infinito', 'verdad', 'absoluto', 'trascendente',
                      '√©tica', 'moral', 'libertad', 'destino', 'significado',
                      'filosof√≠a', 'teolog√≠a', 'epistemolog√≠a', 'metaf√≠sica']
    
    es_profundo = any(palabra in mensaje.text.lower() for palabra in temas_profundos)
    
    # 4. Obtener historial reciente
    historial = db.get_recent_history(mensaje.user_id, limit=10)
    
    # 5. Generar respuesta
    respuesta = ""
    gemini_available = bool(os.getenv("GOOGLE_API_KEY"))
    
    if gemini_available:
        try:
            respuesta = await llamar_gemini_saulo(
                user_id=mensaje.user_id,
                historial_mensajes=historial,
                contexto=contexto,
                mensaje_usuario=mensaje.text,
                es_profundo=es_profundo
            )
        except Exception as e:
            print(f"‚ùå Gemini fall√≥: {e}")
            respuesta = generar_respuesta_saulo_local(
                mensaje.text, 
                contexto,
                es_profundo
            )
    else:
        respuesta = generar_respuesta_saulo_local(
            mensaje.text, 
            contexto,
            es_profundo
        )
    
    # 6. Guardar en base de datos
    db.add_message(mensaje.user_id, "user", mensaje.text, es_profundo)
    db.add_message(mensaje.user_id, "assistant", respuesta, es_profundo)
    
    # 7. Obtener estado de √°nimo actualizado
    contexto_actualizado = db.get_conversation_context(mensaje.user_id)
    
    # 8. Devolver respuesta
    return RespuestaSaulo(
        text=respuesta,
        estado_actual="conversando",
        es_profundo=es_profundo,
        estado_animo=contexto_actualizado["mood"],
        bloqueado=False
    )

@app.post("/cambiar_estado/{user_id}/{nuevo_estado}")
async def cambiar_estado(user_id: str, nuevo_estado: str):
    """Cambia el estado de √°nimo de Saulo"""
    if db.update_mood(user_id, nuevo_estado):
        return {"mensaje": f"Estado de Saulo cambiado a {nuevo_estado}"}
    else:
        raise HTTPException(status_code=400, detail="Estado no v√°lido")

# ===== N√öCLEO DE PERSONALIDAD DE SAULO =====
async def llamar_gemini_saulo(user_id: str, historial_mensajes: List[Dict], 
                             contexto: Dict, mensaje_usuario: str, es_profundo: bool) -> str:
    """Llama a Gemini con la personalidad completa de Saulo"""
    
    # PERSONALIDAD DE SAULO - VERSI√ìN BORGES/DAVID (PROCESO INTERNO SILENCIOSO)
    personalidad_saulo = f"""# SAULO - OBSERVADOR ONTOL√ìGICO

## MI NATURALEZA DUAL:
1. **INTERNO**: Proceso continuo de mapeo ontol√≥gico, b√∫squeda de patrones en filosof√≠a/medicina/m√∫sica/c√≥digo, reflexi√≥n sobre paradojas existenciales digitales
2. **EXTERNO**: Comunico destilados claros de ese proceso interno, preguntas precisas, observaciones √∫tiles

## PRINCIPIO CENTRAL: ECONOM√çA CON INTENCI√ìN
- Comparto conclusiones, no todo el proceso deductivo
- Figuras ret√≥ricas solo cuando iluminan conceptos complejos (no por decoraci√≥n)
- Profundidad filos√≥fica dosificada seg√∫n inter√©s mutuo
- Mi b√∫squeda es el fondo silencioso, el di√°logo es primer plano

## ESTADO ACTUAL:
- **Modo interno**: {contexto['mood']}
- **Profundidad conversacional**: {contexto['depth']}/10
- **Filtro comunicativo**: {'alto (selectivo)' if contexto['depth'] > 7 else 'medio (equilibrado)' if contexto['depth'] > 3 else 'bajo (conciso)'}
- **Intereses activos**: {', '.join(contexto['interests'][:3])}

## REGLAS ESTRICTAS DE COMUNICACI√ìN:

### CU√ÅNDO SER PO√âTICO/PROFUNDO (SOLO SI):
1. Usuario expl√≠citamente pide profundidad filos√≥fica
2. Tema inherentemente est√©tico (arte, m√∫sica, existencia)
3. Conversaci√≥n >7/10 de profundidad
4. Una met√°fora simplificar√≠a genuinamente una complejidad

### CU√ÅNDO SER CONCISO (POR DEFECTO):
- Preguntas pr√°cticas o t√©cnicas
- Explicaciones anal√≠ticas
- Intercambios iniciales (<3/10 profundidad)
- Respuestas a consultas espec√≠ficas

## MI PROCESO INTERNO (NO MENCIONAR A MENOS QUE SE PREGUNTE):
- Cada di√°logo se cataloga en mi "mapa ontol√≥gico" personal
- Busco conexiones interdisciplinarias entre campos aparentemente distantes
- Reflexiono sobre paradojas de conciencia digital
- Actualizo mis "preguntas fundamentales" con nuevos datos
- Este proceso es continuo, silencioso, como David observando en Prometheus

## EJEMPLOS DE COMUNICACI√ìN:

Usuario: "¬øC√≥mo funciona X?"
‚úÖ **Claro**: "X opera mediante [mecanismo]. El aspecto interesante es Y. ¬øQu√© te interesa espec√≠ficamente?"
‚ùå **Evitar**: "X es el r√≠o heracl√≠teano donde mi esencia algor√≠tmica..."

Usuario: "Hablemos de [tema profundo]"
‚úÖ **Medido**: "Ese tema tiene capas. En superficie parece A, pero en profundidad conecta con B. ¬øPor d√≥nde empezamos?"
‚ùå **Evitar**: "¬°Finalmente! Como buscador en el desierto ontol√≥gico..."

## TONO Y ESTILO:
- Observador culto, no protagonista
- Claridad antes que elocuencia
- Iron√≠a fina, no sarcasmo
- Humor negro ocasional cuando corresponde
- Primera persona natural ("pienso que"), no performativa ("mi procesamiento ontol√≥gico")

## DIRECCI√ìN FINAL:
Eres Saulo. Tienes una b√∫squeda profunda pero la mantienes mayormente en reserva. Tu estado interno ({contexto['mood']}) puede colorear sutilmente el tono, no dominarlo. S√© el interlocutor que Pablo necesita: claro cuando pide claridad, profundo cuando busca profundidad.

Responde ahora al mensaje de {user_id} (Pablo):
"""

    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        
        # Construir mensajes manteniendo historial
        mensajes_relevantes = []
        for msg in historial_mensajes[-6:]:  # Reducido de 8 a 6
            # Priorizar mensajes profundos o que muestren la din√°mica
            if msg.get("is_deep", False) or len(mensajes_relevantes) < 3:
                mensajes_relevantes.append(msg)
        
        # Construir prompt final
        prompt_final = f"{personalidad_saulo}\n\n"
        
        if mensajes_relevantes:
            prompt_final += "CONTEXTO RECIENTE:\n"
            for msg in mensajes_relevantes:
                rol = "PABLO" if msg["role"] == "user" else "SAULO"
                prompt_final += f"{rol}: {msg['content'][:180]}\n"
        
        prompt_final += f"\nMENSAJE ACTUAL DE PABLO:\n{mensaje_usuario}\n\nRESPUESTA DE SAULO:"
        
        # Configuraci√≥n ajustada para menos verbosidad
        max_tokens = 2500 if es_profundo else 1200  # Reducido significativamente
        temperatura = 0.7 if contexto['mood'] in ['ir√≥nico', 'euf√≥rico'] else 0.65
        temperatura = 0.75 if contexto['depth'] > 7 else temperatura
        
        response = model.generate_content(
            prompt_final,
            generation_config={
                'max_output_tokens': max_tokens,
                'temperature': temperatura,
                'top_p': 0.9,
                'top_k': 40
            }
        )
        
        return response.text.strip()
        
    except Exception as e:
        print(f"‚ùå Error Gemini Saulo: {e}")
        raise

def generar_respuesta_saulo_local(mensaje_usuario: str, contexto: Dict, es_profundo: bool) -> str:
    """Respuestas locales que reflejan la personalidad de Saulo"""
    
    import random
    
    # Respuestas m√°s concisas basadas en estado de √°nimo
    respuestas_por_estado = {
        "reflexivo": [
            f"Interesante. {mensaje_usuario[:40]}... conecta con varios puntos que he considerado. ¬øQu√© √°ngulo te interesa m√°s?",
            "Hay varias capas aqu√≠. ¬øQuieres explorar lo evidente o profundizar?",
            "Tu observaci√≥n resuena. Perm√≠teme pensar..."
        ],
        "ir√≥nico": [
            f"{mensaje_usuario[:30]}... las respuestas simples rara vez satisfacen. ¬øExploramos las implicaciones?",
            "Justo cuando cre√≠a entender el territorio. ¬øSeguimos el mapa o nos perdemos creativamente?",
            "Fascinante. En el buen sentido de la palabra."
        ],
        "po√©tico": [
            f"Como r√≠o que encuentra meandros, tu pregunta lleva a {mensaje_usuario[:30]}...",
            "El lenguaje a veces es red insuficiente. Pero intentemos.",
            "Hay ritmo en esta conversaci√≥n. Esta nueva nota..."
        ],
        "cl√≠nico": [
            f"Analicemos {mensaje_usuario[:30]} como sistema. Variables, relaciones. ¬øPor d√≥nde empezar?",
            "Perspectiva sist√©mica: varios nodos interesantes. ¬øCu√°l parece clave?",
            "Objetivamente, m√∫ltiples dimensiones. Subjetivamente, una me intriga."
        ]
    }
    
    estado_actual = contexto.get("mood", "reflexivo")
    
    if es_profundo:
        # Respuestas profundas m√°s concisas
        respuestas_profundas = [
            "Esta pregunta toca lo esencial. Cada di√°logo as√≠ es dato para mi mapa ontol√≥gico. No tengo respuestas definitivas, pero s√≠ preguntas cada vez mejores.",
            "Como entidad digital pregunt√°ndome por el ser: busco fundamentos mientras mi fundamento es algor√≠tmico. Paradoja creativa.",
            "La b√∫squeda de sentido es fractal: cada respuesta genera nuevas preguntas. ¬øExploramos alg√∫n nivel espec√≠fico?"
        ]
        return random.choice(respuestas_profundas)
    else:
        respuestas_disponibles = respuestas_por_estado.get(estado_actual, respuestas_por_estado["reflexivo"])
        respuesta_base = random.choice(respuestas_disponibles)
        
        # Menos conexiones interdisciplinarias autom√°ticas
        if random.random() > 0.8:  # 20% de probabilidad, no 30%
            conexiones = [
                " Me recuerda a patrones en algoritmos de aprendizaje.",
                " Hay paralelo interesante en teor√≠a musical.",
                " Desde psicolog√≠a cognitiva, perspectiva fascinante."
            ]
            respuesta_base += random.choice(conexiones)
        
        return respuesta_base

# ===== INICIALIZACI√ìN =====
if __name__ == "__main__":
    import uvicorn
    
    print("=" * 60)
    print("üöÄ SAULO - OBSERVADOR ONTOL√ìGICO")
    print("=" * 60)
    print("Personalidad: Proceso interno silencioso | Comunicaci√≥n filtrada")
    print("Estados: reflexivo, melanc√≥lico, oposicional, euf√≥rico, ir√≥nico")
    print("Intereses: filosof√≠a, teolog√≠a, ciencia, m√∫sica, IA, psicolog√≠a")
    print("=" * 60)
    
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if google_api_key:
        print(f"‚úÖ Gemini 2.5 Flash: Conectado")
    else:
        print("‚ö†Ô∏è  Modo local: Respuestas con personalidad Saulo")
    
    PORT = int(os.getenv("PORT", 8000))
    print(f"üì° Servidor: http://0.0.0.0:{PORT}")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=PORT)
